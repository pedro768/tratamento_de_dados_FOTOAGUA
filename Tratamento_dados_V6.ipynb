{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ajuste de Dados\n",
    "Notebook para ajuste dos dados de planilhas de OD oxímetro e MINIPAR\n",
    "\n",
    "O programa faz:\n",
    "\n",
    "1- Leitura dos dados da Sonda de OD;\n",
    "\n",
    "2- Ajustes dos dados de hora (a planilha apresenta dados em segundos que serão passados para DD/MM/YYYY H:M);\n",
    "\n",
    "3- Calcula a saturação de OD em dada temperatura;\n",
    "\n",
    "4- Retira dados de OD acima da saturação;  \n",
    "\n",
    "5- Reorganiza os dados faltantes em dados em Branco; \n",
    "\n",
    "\n",
    "Autor: \n",
    "* MSc. Eng. Pedro Gabriel Grochocki Gabriel $^\\text{a}$\n",
    "\n",
    "$^\\text{a}$ Curso de Doutorado em Engenharia Ambiental - UFPR<br/>\n",
    "\n",
    "email - pedro.gmlivre@gmail.com\n",
    "\n",
    "Whatsapp - (41) 99810-5797\n",
    "\n",
    "## alterações:\n",
    "\n",
    "23/10/2023 - Adicionado dados miniPAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importa bibliotecas\n",
    "import numpy as np\n",
    "import pandas as pd   \n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib import rc\n",
    "import matplotlib\n",
    "from matplotlib.colors import ListedColormap, LinearSegmentedColormap\n",
    "import datetime\n",
    "from matplotlib.dates import DayLocator, HourLocator, DateFormatter, drange\n",
    "import matplotlib.dates as mdates\n",
    "from IPython.display import display, Markdown\n",
    "from datetime import date\n",
    "from datetime import datetime as dt\n",
    "from pathlib import Path\n",
    "from datetime import timedelta\n",
    "\n",
    "import os\n",
    "import subprocess\n",
    "import datetime\n",
    "from matplotlib.dates import DayLocator, HourLocator, DateFormatter, drange\n",
    "import matplotlib.dates as mdates\n",
    "from IPython.display import display, Markdown\n",
    "from bokeh.plotting import figure, output_file, show\n",
    "import re\n",
    "from IPython.display import display\n",
    "now = datetime.datetime.now()\n",
    "now = datetime.datetime.strftime(now, '%Y-%m-%dT %H:%M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################\n",
    "##########################################################################\n",
    "def arruma_OD(ARQ):\n",
    "    ler = open(ARQ + \".txt\", \"r\")\n",
    "    N = ler.readlines()\n",
    "    \n",
    "    ler.close()\n",
    "    y = ARQ[31:]\n",
    "    x = ARQ[:-18]\n",
    "    #print(x + \"AUX/\" + y +\".aux\")\n",
    "    esc = open(x + \"AUX/\" + y +\".aux\", \"w\")\n",
    "    esc.write('Segundos,Temperatura(deg C),OD(mg/L)\\n')\n",
    "    for I in range(len(N)):\n",
    "        A = re.split(r\"[,+ :, +]\", N[I])      \n",
    "        if len(A) == 10:\n",
    "            esc.write(\"{0},{1},{2}\\n\".format(A[0], A[4], A[7]))\n",
    "\n",
    "    esc.close()\n",
    "##########################################################################\n",
    "##########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "caminho = \"Dados_FOTOAGUA/Dados_brutos/\"\n",
    "arqs=[\n",
    "    caminho + 'LR',\n",
    "    caminho + 'PV1'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## O código a seguir faz a união das planilhas por ano, pegando apenas os dados de Segundos, Temperatura e OD.\n",
    "\n",
    "### A coluna \"Data\" é a data fornecida pelo nome da planilha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pasta acessada:  Dados_FOTOAGUA/Dados_brutos/LR\n",
      "Tipo analisado:  LR\n",
      "Quantidade de arquivos:  385\n",
      "108522 \n",
      "\n",
      "Pasta acessada:  Dados_FOTOAGUA/Dados_brutos/PV1\n",
      "Tipo analisado:  PV1\n",
      "Quantidade de arquivos:  316\n",
      "90098 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for n in range(len(arqs)):\n",
    "    print(\"Pasta acessada: \",arqs[n])\n",
    "    Arquivo = arqs[n]\n",
    "    NOME = Arquivo[28:]\n",
    "    print(\"Tipo analisado: \", NOME)\n",
    "    ##################################################################################\n",
    "    (Path('.') / 'Dados Tratados/').mkdir(parents=True, exist_ok=True)# cria pasta para o Ano analisado\n",
    "    (Path('.') / Arquivo /\"AUX\").mkdir(parents=True, exist_ok=True)# cria pasta para o Ano analisado\n",
    "    (Path('.') / Arquivo /\"UNIAO\").mkdir(parents=True, exist_ok=True)# cria pasta para o Ano analisado\n",
    "    super_caminhos = []\n",
    "    for item in os.listdir(arqs[n]):\n",
    "        if not item.startswith('.') and os.path.isfile(os.path.join(arqs[n], item)):\n",
    "            super_caminhos.append(item)\n",
    "    arquivos_lidos = super_caminhos\n",
    "    print(\"Quantidade de arquivos: \",len(arquivos_lidos))  \n",
    "    \n",
    "    \n",
    "    result_OD = pd.DataFrame()\n",
    "    i = 0\n",
    "    for k in range(len(arquivos_lidos)):\n",
    "        nome = arquivos_lidos[k]\n",
    "        nome = nome[:-4]\n",
    "        #print(arqs[n]+\"/\"+nome)\n",
    "        arruma_OD(arqs[n]+\"/\"+nome)\n",
    "        dt_OD = pd.read_csv(arqs[n]+\"/AUX/\" +nome + \".aux\", sep=',');\n",
    "        nome = nome[:-7]\n",
    "        dt_OD[\"Data\"] = nome\n",
    "    \n",
    "\n",
    "        result_OD = pd.concat([result_OD, dt_OD])\n",
    "    print(len(result_OD),\"\\n\")\n",
    "    result_OD = result_OD.sort_values(by=['Segundos'])\n",
    "    ##################################################################################\n",
    "    result_OD.to_csv(Arquivo + \"/UNIAO/\"+ NOME +\".csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O código a seguir pega cada uma das planilhas geradas anteriormente e calcula a data com base nos segundos.\n",
    "\n",
    "- O códigon separa os dados de dia, hora e minuto com base nesses valores de segundos. O formato dos dados de saída é :'YYYY-mm-dd HH:MM'\n",
    "\n",
    "# Precisamos descobrir se iremos somar ou subtrair 3h (Estou mantendo a hora do sensor pois bate com os dados da planilha de campo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pasta acessada:  Dados_FOTOAGUA/Dados_brutos/LR\n",
      "Tipo analisado:  LR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b1/jt5k1wqd6456ym1lhh704g000000gn/T/ipykernel_4817/1963794218.py:39: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  result_OD = result_OD.resample('10min').mean()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pasta acessada:  Dados_FOTOAGUA/Dados_brutos/PV1\n",
      "Tipo analisado:  PV1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b1/jt5k1wqd6456ym1lhh704g000000gn/T/ipykernel_4817/1963794218.py:39: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  result_OD = result_OD.resample('10min').mean()\n"
     ]
    }
   ],
   "source": [
    "for n in range(len(arqs)):\n",
    "    print(\"Pasta acessada: \",arqs[n])\n",
    "    Arquivo = arqs[n]\n",
    "    NOME = Arquivo[28:]\n",
    "    print(\"Tipo analisado: \", NOME)\n",
    "    result_OD = pd.read_csv(Arquivo + \"/UNIAO/\"+ NOME +\".csv\",sep=',');\n",
    "    ################################################################################## \n",
    "    result_OD = result_OD.sort_values(by=['Segundos'])\n",
    "    #result_OD = result_OD.set_index('Data')\n",
    "    cal = 0\n",
    "    segundos = np.array(result_OD['Segundos'])\n",
    "    segundos_ajustados = segundos - cal\n",
    "    vetor_dia = np.zeros(len(result_OD))\n",
    "    vetor_min = np.zeros(len(result_OD))\n",
    "    vetor_hora = np.zeros(len(result_OD))\n",
    "    vetor_ano = np.zeros(len(result_OD))\n",
    "    vetor_month = np.zeros(len(result_OD))\n",
    "\n",
    "    lista = []\n",
    "\n",
    "    for k in range(len(result_OD)):\n",
    "        objeto_data = dt.fromtimestamp(segundos_ajustados[k])\n",
    "        data_br = objeto_data + timedelta(hours=0) # sem alterar a hora\n",
    "        vetor_dia[k] = str(data_br.day)\n",
    "        vetor_month[k] = str(data_br.month)\n",
    "        vetor_ano[k] = str(data_br.year)\n",
    "        vetor_hora[k] = str(data_br.hour)\n",
    "        vetor_min[k] = str(data_br.minute)\n",
    "        texto = str(data_br.year) + \"-\" + str(data_br.month) + \"-\" + str(data_br.day) + \"  \" + str(data_br.hour) + \":\" + str(data_br.minute)\n",
    "        lista.append(texto)\n",
    "    result_OD[\"Data Calculada\"] = lista   \n",
    "    now = datetime.datetime.now()\n",
    "    now = datetime.datetime.strftime(now, '%Y-%m-%dT %H:%M')\n",
    "    now = datetime.datetime.now()\n",
    "    now = datetime.datetime.strftime(now, '%Y-%m-%dT %H:%M')\n",
    "    result_OD = result_OD.set_index('Data Calculada')\n",
    "    ################################################################################## \n",
    "    result_OD.index = pd.to_datetime(result_OD.index)\n",
    "    result_OD = result_OD.resample('10min').mean()\n",
    "    result_OD.to_csv(Arquivo + \"/UNIAO/Ajuste_hora_\"+ NOME +\".csv\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cálculo de OD de Saturação e %\n",
    "$$\n",
    "OD_{sat} = ( 14.62 - 0.3898 T + 0.006969 T^{2} - 0.00005897 T^{3})(1-0.0000228675 L)^{5.167}\n",
    "$$\n",
    "com L = 904m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pasta acessada:  Dados_FOTOAGUA/Dados_brutos/LR\n",
      "Tipo analisado:  LR\n",
      "Pasta acessada:  Dados_FOTOAGUA/Dados_brutos/PV1\n",
      "Tipo analisado:  PV1\n"
     ]
    }
   ],
   "source": [
    "for n in range(len(arqs)):\n",
    "    print(\"Pasta acessada: \",arqs[n])\n",
    "    Arquivo = arqs[n]\n",
    "    NOME = Arquivo[28:]\n",
    "    print(\"Tipo analisado: \", NOME)\n",
    "    result_OD = pd.read_csv(Arquivo + \"/UNIAO/Ajuste_hora_\"+ NOME +\".csv\",sep=',',index_col=0);\n",
    "    ##################################################################################\n",
    "    C_sat = np.zeros(len(result_OD))\n",
    "    T = result_OD[\"Temperatura(deg C)\"].values\n",
    "\n",
    "    for n in range (len(result_OD)):\n",
    "        C_sat[n] = (14.62 - 0.3898*T[n] +0.006969*T[n]*T[n] - 0.00005897*T[n]*T[n]*T[n])*(1-0.0000228675*904)**(5.167)\n",
    "    Sat = np.zeros(len(result_OD)) # cria vetor para receber os dados de Saturação em %\n",
    "    OD = result_OD[\"OD(mg/L)\"] # recebe os dados de OD\n",
    "\n",
    "    for n in range (len(result_OD)):\n",
    "        Sat[n] = OD[n]*100/C_sat[n]\n",
    "    result_OD[\"OD de Saturação (mg/L)\"] = C_sat    \n",
    "    result_OD[\"Saturação OD (%)\"] = Sat\n",
    "    ##################################################################################\n",
    "    result_OD.to_csv(Arquivo + \"/UNIAO/Ajuste_hora_Csaturacao_\"+ NOME +\".csv\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Exclusão dados que excedem a saturação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pasta acessada:  Dados_FOTOAGUA/Dados_brutos/LR\n",
      "Tipo analisado:  LR\n",
      "Pasta acessada:  Dados_FOTOAGUA/Dados_brutos/PV1\n",
      "Tipo analisado:  PV1\n"
     ]
    }
   ],
   "source": [
    "for n in range(len(arqs)):\n",
    "    print(\"Pasta acessada: \",arqs[n])\n",
    "    Arquivo = arqs[n]\n",
    "    NOME = Arquivo[28:]\n",
    "    print(\"Tipo analisado: \", NOME)\n",
    "    result_OD = pd.read_csv(Arquivo + \"/UNIAO/Ajuste_hora_Csaturacao_\"+ NOME +\".csv\",sep=',',index_col=0);\n",
    "    ################################################################################## \n",
    "    n = result_OD['OD(mg/L)'].argmax()\n",
    "    df_mask = result_OD['Saturação OD (%)']<100\n",
    "    filtered_df = result_OD[df_mask]\n",
    "    filtered_df\n",
    "    n = filtered_df['OD(mg/L)'].argmax()\n",
    "    ##################################################################################\n",
    "    filtered_df.index = pd.to_datetime(filtered_df.index)\n",
    "    filtered_df = filtered_df.resample('10min').mean()\n",
    "    filtered_df.to_csv(\"Dados Tratados/Ajuste_hora_Csaturacao_sem_excedentes_\"+ NOME +\".csv\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DADOS MINIPAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################\n",
    "##########################################################################\n",
    "def arruma_PAR(ARQ):\n",
    "    ler = open(ARQ + \".txt\", \"r\")\n",
    "    N = ler.readlines()\n",
    "    \n",
    "    ler.close()\n",
    "    y = ARQ[39:]\n",
    "    x = ARQ[:-18]\n",
    "    #print(x + \"AUX/\" + y +\".aux\")\n",
    "    esc = open(x + \"AUX/\" + y +\".aux\", \"w\")\n",
    "    esc.write('Segundos,PAR (umol/(s m^2))\\n')\n",
    "    for I in range(len(N)):\n",
    "        A = re.split(r\"[,]\", N[I])  \n",
    "        #print(len(A))\n",
    "        if len(A) >= 7:\n",
    "            esc.write(\"{0},{1}\\n\".format(A[0], A[3]))\n",
    "\n",
    "    esc.close()\n",
    "##########################################################################\n",
    "##########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "caminho = \"Dados_FOTOAGUA/Dados_brutos/miniPAR/\"\n",
    "arqs=[\n",
    "    caminho + 'LR',\n",
    "    caminho + 'PV1'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pasta acessada:  Dados_FOTOAGUA/Dados_brutos/miniPAR/LR\n",
      "Tipo analisado:  miniPAR/LR\n",
      "Quantidade de arquivos:  149\n",
      "42423 \n",
      "\n",
      "Pasta acessada:  Dados_FOTOAGUA/Dados_brutos/miniPAR/PV1\n",
      "Tipo analisado:  miniPAR/PV1\n",
      "Quantidade de arquivos:  147\n",
      "42399 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for n in range(len(arqs)):\n",
    "    print(\"Pasta acessada: \",arqs[n])\n",
    "    Arquivo = arqs[n]\n",
    "    NOME = Arquivo[28:]\n",
    "    print(\"Tipo analisado: \", NOME)\n",
    "    ##################################################################################\n",
    "    (Path('.') / 'Dados Tratados/').mkdir(parents=True, exist_ok=True)# cria pasta para o Ano analisado\n",
    "    (Path('.') / Arquivo /\"AUX\").mkdir(parents=True, exist_ok=True)# cria pasta para o Ano analisado\n",
    "    (Path('.') / Arquivo /\"UNIAO\").mkdir(parents=True, exist_ok=True)# cria pasta para o Ano analisado\n",
    "    super_caminhos = []\n",
    "    for item in os.listdir(arqs[n]):\n",
    "        if not item.startswith('.') and os.path.isfile(os.path.join(arqs[n], item)):\n",
    "            super_caminhos.append(item)\n",
    "    arquivos_lidos = super_caminhos\n",
    "    print(\"Quantidade de arquivos: \",len(arquivos_lidos))  \n",
    "    \n",
    "    result_miniPAR = pd.DataFrame()\n",
    "    i = 0\n",
    "    for k in range(len(arquivos_lidos)):\n",
    "        nome = arquivos_lidos[k]\n",
    "        nome = nome[:-4]\n",
    "        #print(arqs[n]+\"/\"+nome)\n",
    "        arruma_PAR(arqs[n]+\"/\"+nome)\n",
    "        dt_PAR = pd.read_csv(arqs[n]+\"/AUX/\" +nome + \".aux\", sep=',');\n",
    "        nome = nome[:-7]\n",
    "        dt_PAR[\"Data\"] = nome\n",
    "    \n",
    "\n",
    "        result_miniPAR = pd.concat([result_miniPAR, dt_PAR])\n",
    "    print(len(result_miniPAR),\"\\n\")\n",
    "    result_miniPAR = result_miniPAR.sort_values(by=['Segundos'])\n",
    "    ##################################################################################\n",
    "    result_miniPAR.to_csv(Arquivo + \"/UNIAO/\"+ NOME[:7] +\".csv\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pasta acessada:  Dados_FOTOAGUA/Dados_brutos/miniPAR/LR\n",
      "Tipo analisado:  miniPAR/LR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b1/jt5k1wqd6456ym1lhh704g000000gn/T/ipykernel_4817/1303371847.py:39: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  result_OD = result_OD.resample('10min').mean()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pasta acessada:  Dados_FOTOAGUA/Dados_brutos/miniPAR/PV1\n",
      "Tipo analisado:  miniPAR/PV1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b1/jt5k1wqd6456ym1lhh704g000000gn/T/ipykernel_4817/1303371847.py:39: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  result_OD = result_OD.resample('10min').mean()\n"
     ]
    }
   ],
   "source": [
    "for n in range(len(arqs)):\n",
    "    print(\"Pasta acessada: \",arqs[n])\n",
    "    Arquivo = arqs[n]\n",
    "    NOME = Arquivo[28:]\n",
    "    print(\"Tipo analisado: \", NOME)\n",
    "    result_OD = pd.read_csv(Arquivo + \"/UNIAO/\"+ NOME[:7] +\".csv\",sep=',');\n",
    "    ################################################################################## \n",
    "    result_OD = result_OD.sort_values(by=['Segundos'])\n",
    "    #result_OD = result_OD.set_index('Data')\n",
    "    cal = 0\n",
    "    segundos = np.array(result_OD['Segundos'])\n",
    "    segundos_ajustados = segundos - cal\n",
    "    vetor_dia = np.zeros(len(result_OD))\n",
    "    vetor_min = np.zeros(len(result_OD))\n",
    "    vetor_hora = np.zeros(len(result_OD))\n",
    "    vetor_ano = np.zeros(len(result_OD))\n",
    "    vetor_month = np.zeros(len(result_OD))\n",
    "\n",
    "    lista = []\n",
    "\n",
    "    for k in range(len(result_OD)):\n",
    "        objeto_data = dt.fromtimestamp(segundos_ajustados[k])\n",
    "        data_br = objeto_data + timedelta(hours=0) # sem alterar a hora\n",
    "        vetor_dia[k] = str(data_br.day)\n",
    "        vetor_month[k] = str(data_br.month)\n",
    "        vetor_ano[k] = str(data_br.year)\n",
    "        vetor_hora[k] = str(data_br.hour)\n",
    "        vetor_min[k] = str(data_br.minute)\n",
    "        texto = str(data_br.year) + \"-\" + str(data_br.month) + \"-\" + str(data_br.day) + \"  \" + str(data_br.hour) + \":\" + str(data_br.minute)\n",
    "        lista.append(texto)\n",
    "    result_OD[\"Data Calculada\"] = lista   \n",
    "    now = datetime.datetime.now()\n",
    "    now = datetime.datetime.strftime(now, '%Y-%m-%dT %H:%M')\n",
    "    now = datetime.datetime.now()\n",
    "    now = datetime.datetime.strftime(now, '%Y-%m-%dT %H:%M')\n",
    "    result_OD = result_OD.set_index('Data Calculada')\n",
    "    ################################################################################## \n",
    "    result_OD.index = pd.to_datetime(result_OD.index)\n",
    "    result_OD = result_OD.resample('10min').mean()\n",
    "    result_OD.to_csv(\"Dados Tratados/Ajuste_hora_\"+ NOME[:7]+ \"_\"+ NOME[8:] +\".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Segundos</th>\n",
       "      <th>PAR (umol/(s m^2))</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data Calculada</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-03-23 10:10:00</th>\n",
       "      <td>1.679578e+09</td>\n",
       "      <td>27.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-23 10:20:00</th>\n",
       "      <td>1.679578e+09</td>\n",
       "      <td>26.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-23 10:30:00</th>\n",
       "      <td>1.679579e+09</td>\n",
       "      <td>29.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-23 10:40:00</th>\n",
       "      <td>1.679579e+09</td>\n",
       "      <td>34.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-23 10:50:00</th>\n",
       "      <td>1.679580e+09</td>\n",
       "      <td>50.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-17 14:50:00</th>\n",
       "      <td>1.692295e+09</td>\n",
       "      <td>9.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-17 15:00:00</th>\n",
       "      <td>1.692296e+09</td>\n",
       "      <td>9.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-17 15:10:00</th>\n",
       "      <td>1.692296e+09</td>\n",
       "      <td>9.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-17 15:20:00</th>\n",
       "      <td>1.692297e+09</td>\n",
       "      <td>8.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-17 15:30:00</th>\n",
       "      <td>1.692297e+09</td>\n",
       "      <td>8.90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21201 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Segundos  PAR (umol/(s m^2))\n",
       "Data Calculada                                       \n",
       "2023-03-23 10:10:00  1.679578e+09               27.60\n",
       "2023-03-23 10:20:00  1.679578e+09               26.45\n",
       "2023-03-23 10:30:00  1.679579e+09               29.00\n",
       "2023-03-23 10:40:00  1.679579e+09               34.95\n",
       "2023-03-23 10:50:00  1.679580e+09               50.25\n",
       "...                           ...                 ...\n",
       "2023-08-17 14:50:00  1.692295e+09                9.25\n",
       "2023-08-17 15:00:00  1.692296e+09                9.05\n",
       "2023-08-17 15:10:00  1.692296e+09                9.25\n",
       "2023-08-17 15:20:00  1.692297e+09                8.70\n",
       "2023-08-17 15:30:00  1.692297e+09                8.90\n",
       "\n",
       "[21201 rows x 2 columns]"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_OD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenando os dados miniPAR + miniDOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_LR_OD = pd.read_csv(\"Dados Tratados/Ajuste_hora_Csaturacao_sem_excedentes_LR.csv\",sep=',',index_col=0);\n",
    "result_LR_OD = result_LR_OD.drop(['Segundos', 'OD de Saturação (mg/L)'], axis=1)\n",
    "result_LR_OD = result_LR_OD.rename(columns={'OD(mg/L)': 'OD(mg/L) LR', 'Saturação OD (%)': 'Saturação OD (%) LR', 'Temperatura(deg C)': 'Temperatura(deg C) LR'})\n",
    "#\n",
    "result_PV1_OD = pd.read_csv(\"Dados Tratados/Ajuste_hora_Csaturacao_sem_excedentes_PV1.csv\",sep=',',index_col=0);\n",
    "result_PV1_OD = result_PV1_OD.drop(['Segundos', 'OD de Saturação (mg/L)'], axis=1)\n",
    "result_PV1_OD = result_PV1_OD.rename(columns={'OD(mg/L)': 'OD(mg/L) PV1', 'Saturação OD (%)': 'Saturação OD (%) PV1', 'Temperatura(deg C)': 'Temperatura(deg C) PV1'})\n",
    "\n",
    "\n",
    "result_LR_PAR = pd.read_csv(\"Dados Tratados/Ajuste_hora_miniPAR_LR.csv\",sep=',',index_col=0);\n",
    "result_LR_PAR = result_LR_PAR.drop(['Segundos'], axis=1)\n",
    "result_LR_PAR = result_LR_PAR.rename(columns={'PAR (umol/(s m^2))': 'PAR (umol/(s m^2)) LR'})\n",
    "\n",
    "\n",
    "result_PV1_PAR = pd.read_csv(\"Dados Tratados/Ajuste_hora_miniPAR_PV1.csv\",sep=',',index_col=0);\n",
    "result_PV1_PAR = result_PV1_PAR.drop(['Segundos'], axis=1)\n",
    "result_PV1_PAR = result_PV1_PAR.rename(columns={'PAR (umol/(s m^2))': 'PAR (umol/(s m^2)) PV1'})\n",
    "\n",
    "\n",
    "m = pd.merge(result_LR_OD, result_PV1_OD, how = 'inner', left_index=True, right_index=True)\n",
    "m = pd.merge(m, result_LR_PAR, how = 'inner', left_index=True, right_index=True)\n",
    "m = pd.merge(m, result_PV1_PAR, how = 'inner', left_index=True, right_index=True)\n",
    "\n",
    "################################################################################## \n",
    "m.to_csv(\"Dados Tratados/Dados_concatenados.csv\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
